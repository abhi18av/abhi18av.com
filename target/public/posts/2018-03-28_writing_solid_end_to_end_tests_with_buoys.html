<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"><meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"><meta content="width=device-width, initial-scale=1.0, user-scalable=no" name="viewport"><link href="/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"><link href="/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"><link href="/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"><link href="/manifest.json" rel="manifest"><link color="#5bbad5" href="/safari-pinned-tab.svg" rel="mask-icon"><meta content="#ffffff" name="theme-color"><link href="/css/normalize.css" rel="stylesheet"><link href="/css/app.css" rel="stylesheet"><title>Writing solid End-to-End-Tests with Buoys - 200ok</title><link href="/rss.xml" rel="alternate" title="200ok - Consultancy, Research Lab, Incubator" type="application/rss+xml"><link href="/atom.xml" rel="alternate" title="200ok - Consultancy, Research Lab, Incubator" type="application/atom+xml"><meta content="Writing solid End-to-End-Tests with Buoys - 200ok" property="og:title"><meta content="article" property="og:type"><meta property="og:description"><meta content="https://200ok.ch/posts/2018-03-28_writing_solid_end_to_end_tests_with_buoys.html" property="og:url"><meta content="https://200ok.ch/img/logo.png" property="og:image"><meta content="summary" name="twitter:card"><meta content="@twohundredok" name="twitter:site"><meta content="Writing solid End-to-End-Tests with Buoys - 200ok" name="twitter:title"><meta content="https://200ok.ch/img/logo.png" name="twitter:image"><meta name="twitter:description"><link href="https://200ok.ch/posts/2018-03-28_writing_solid_end_to_end_tests_with_buoys.html" rel="canonical"><link href="/css/styles/solarized-light.css" rel="stylesheet"></head><body id="blog" itemscope itemtype="http://schema.org/Blog"><div class="top-bar"><div class="top-bar-left"><top-bar-title itemprop="image"><a href="/" id="logo"><img src="/img/200ok.svg"></a></top-bar-title></div><div class="top-bar-right"><ul class="menu"><li><a href="/blog.html">Blog</a></li><li><a href="/projects.html">Projects</a></li><li><a href="/team.html">Team</a></li><li><a href="/atom.xml" id="atom-feed"><span>&nbsp;</span>Feed</a></li></ul></div></div><main class="single-post"><div id="content"><article class="blog-post" itemscope itemtype="https://schema.org/BlogPosting"><h3 class="headline" itemprop="headline"><a class="nunito" href="/posts/2018-03-28_writing_solid_end_to_end_tests_with_buoys.html" itemprop="url">Writing solid End-to-End-Tests with Buoys</a></h3><div class="subheader"><p class="post-meta"><time itemprop="datePublished">2018-03-31</time> - <span itemprop="wordCount">1509</span> words - <span itemprop="timeRequired">9</span> min read</p><div class="byline"><img class="author-icon" src="/img/author.svg"><section class="author" itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="name">Phil Hofmann</span></section><section class="author" itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="name">Alain M. Lafon</span></section></div></div><span itemprop="image" itemscope itemtype="https://schema.org/ImageObject"><meta content="190" itemprop="height"><meta content="349" itemprop="width"><meta content="https://200ok.ch/img/logo.png" itemprop="url"></span><div><div class="article-body" itemprop="articleBody"><p><em>Testing</em> deserves and requires it’s own spot in the development plan. It is understandable to only plan ahead sparingly, because many developers dislike testing. They tend to test gently, subconsciously knowing where the code will break and avoiding the weak spots. However, with the proper training and setup, you can find your bugs <em>now</em> and not later.</p>
<p>Finding bugs is somewhat like fishing with a net. At 200ok, we use fine, small nets (unit tests) to catch small fish, and big, coarse nets (integration tests) to catch the killer sharks.</p>
<p>We encourage you to start testing as soon as you have code.</p>
<p>Our mantra is: <em>Test early. Test often. Test Automatically.</em></p>
<p>Writing End-to-End-Tests will improve the quality of your application for some simple reasons:</p>
<ul>
<li>Before you’ve written any code, you know how you want it to behave</li>
<li>Test software against a specification
<ul>
<li>Evaluate a program’s correctness after a change</li>
<li>Yields examples for other developers</li>
</ul></li>
</ul>
<p>It’s proven that using Test-Driven-Development (TDD) practices, your code will have better design and less bugs. For example, <a href="https://www.microsoft.com/en-us/research/blog/exploding-software-engineering-myths/">Microsoft found</a> in a study across multiple teams and products that TDD teams produce code with a 60-90% better defect density</p>
<ul>
<li>TDD Teams also take about 15-35% longer to complete projects</li>
<li>The trade-off is significantly reduced post-release maintenance costs, since code quality is so much better</li>
</ul>
<p>Having said that, writing good End-to-End-Tests (aka. Integration- or Feature-Tests) is not trivial and therefore not favored by some programmers. One reason is that compared to other tests, they are rather unwieldy. More important though, when written without the proper guideline, they will often be brittle.</p>
<p>End-to-End-Tests, as the name suggest, have to integrate the whole system, and thus there is probably not much we can do about <em>unwieldy</em>, apart from having a nice DSL to make them more concise and thus more readable.</p>
<p>However, even if they are rather slow, they are comparatively fast compared to do integration testing by hand. Why? For every new feature developed, there is an exponential amount of work to be done for regression testing. Let’s compare the effort of manually testing an application over time (as more features are developed) with automated Integration-Tests.</p>
<!-- Gnuplot Graph -->
<!--
ManualTesting(x) = x**2
AutomatedTesting(x) = x**1.2+4
set xlabel "Features in application" font "Helvetica,15"
set ylabel "Time to test all features" font "Helvetica,15"
set tics font "Helvetica,15"
set xtics 1
set grid
plot [t=0:5] ManualTesting(t), AutomatedTesting(t)
-->
<p>With automated tests, you leave the hard, repetitive and boring work to the machine. Those kinds of jobs, machines are very good at - whereas humans get bored and make mistakes on repetitive tasks.</p>
<figure>
<img src="/img/2018-03/save_time_with_tests.png" alt="Save time with Tests" /><figcaption>Save time with Tests</figcaption>
</figure>
<p>As you can see, there definitively is an initial overhead of writing integration tests compared to testing by hand. However, as soon as some more features are developed, the automated test suite gains quickly and overtakes the manual testing process.</p>
<p>Note: Consider the math of the graph above as a rule of thumb. The actual effort for both automated tests and manual tests are very different for different kinds of programs. Therefore this is nothing more than a rough sketch, not an actual scientifically proven fact for every scenario.</p>
<p>So, yes, compared to other kinds of automated tests, Integration-Tests are unwieldy and slow. However, compared to the only other solution (manual testing), they are very fast!</p>
<p>Having spoken about speed, we should speak about brittleness.</p>
<h3 id="brittle-typical-end-to-end-tests">Brittle (typical) End-to-End-Tests</h3>
<p>A typical End-To-End-Test visits a page in the application, simulates some user interactions, like filling in a form and clicking a button or a link, and then asserts certain facts about the resulting page.</p>
<p>Over the years, we found that End-To-End-Tests often break, when there is work done in the markup or even in the design. The feature might still work perfectly fine, but the tests did use some implementation detail like a name or a CSS class that isn’t being used anymore - and voilà: the tests fails. This is unacceptable. It costs time and resources to fix these tests even though the code works and there is no regression. Such a test doesn’t fullfill its duty as a warning system for regressions, it is a false positive. And a warning system that has too many false alarms is of no use. With too many false alarms no one will duck and cover when the real alarm sounds. So let’s fix those false positives.</p>
<p>The following example uses <a href="http://rspec.info/">Rspec</a> (with <a href="https://github.com/teamcapybara/capybara">Capybara</a>). This is a setup in a typical Rails app, but the overall strategy to solve the discussed issues can be applied in any technology stack. Capybara is very expressive, so it’ll be easy for you to transpose the knowledge to a different stack.</p>
<p>Let’s start with a typical – a brittle – test.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode ruby"><code class="sourceCode ruby"><a class="sourceLine" id="cb1-1" title="1">describe <span class="st">&#39;Login&#39;</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb1-2" title="2">  it <span class="st">&#39;logs the user in&#39;</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb1-3" title="3">    visit <span class="ch">&#39;/&#39;</span></a>
<a class="sourceLine" id="cb1-4" title="4">    fill_in <span class="st">&#39;user_email&#39;</span>, <span class="st">with: &#39;foo@bar.com&#39;</span></a>
<a class="sourceLine" id="cb1-5" title="5">    fill_in <span class="st">&#39;user_password&#39;</span>, <span class="st">with: &#39;secret&#39;</span></a>
<a class="sourceLine" id="cb1-6" title="6">    find(<span class="st">&#39;.login&#39;</span>).click</a>
<a class="sourceLine" id="cb1-7" title="7">    expect(page).to have_selector(<span class="st">&#39;.dashboard&#39;</span>)</a>
<a class="sourceLine" id="cb1-8" title="8">  <span class="kw">end</span></a>
<a class="sourceLine" id="cb1-9" title="9"><span class="kw">end</span></a></code></pre></div>
<p>The test goes to the root page, fills in the login form, submits it and then asserts the existence of an element with a specific class on the resulting page. To do that, it needs to reference elements in the page and that’s OK. However, the test is tightly coupled to implementation details, like: The email field is named <code>user_email</code>, the password field is named <code>user_password</code>, the submit button has the class <code>login</code>, and the resulting page has an element with the class <code>dashboard</code>. That makes it a brittle test!</p>
<p>The origin for all these names and classes are beyond the scope of an Integration-Test. The names of the form are likely coupled with the model and for the CSS classes it’s likely that some CSS styles are attached to these classes for layouting purposes.</p>
<p>Having established that the origin of the names are beyond the scope of the test means that these names might change at <em>any time</em>. This leads to a situation where the test will fail and give a false positive. The feature still works, but the test fails because the feature has been implemented in a different way.</p>
<p>To solve this issue, it’s good practice to introduce a CSS namespace for testing. Let’s prefix the existing names with <code>test-</code>. In our test, we used two CSS classes <code>login</code> and <code>dashboard</code>, so we introduce <code>test-login</code> and <code>test-dashboard</code>. Let us call these classes <strong>buoys</strong>.</p>
<h3 id="introducing-buoys">Introducing Buoys</h3>
<p>In our markup, we add the buoy <code>test-login</code> to the submit button and the buoy <code>test-dashboard</code> to the element with the class <code>dashboard</code> on the resulting page. In our test, we will replace the existing references to CSS classes with our new namespaced classes.</p>
<p>For form fields it’s more tricky. As the function <code>fill_in</code> only takes an id (or name), but we still want to use our buoys, we will have to add one level of indirection. First we have to find the element in question and then we query it for its name to use that as the first argument to <code>fill_in</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode ruby"><code class="sourceCode ruby"><a class="sourceLine" id="cb2-1" title="1">input = find(<span class="st">:css</span>, <span class="st">&#39;.test_user_email&#39;</span>)</a>
<a class="sourceLine" id="cb2-2" title="2">fill_in input[<span class="st">:name</span>], <span class="st">with: &#39;foo@bar.com&#39;</span></a></code></pre></div>
<p>We do this likewise for all form fields. By doing so, we gain multiple benefits: Through namespacing, we avoid naming conflicts. Using a dedicated namespace in CSS for writing tests makes the references from tests to markup and CSS explicit in both directions. Before, we could read a test and see that it referenced elements in the markup via a CSS selector or other means. But there was no way to read the markup and see that an element is of significance to a test.</p>
<p>Now, if we’re refactoring the markup and we see a class like <code>test-login</code> on a button, we can assume that at least one test will use that class to identify the login button, and if it gets lost during refactoring, we expect that test to fail. Hence, it raises awareness that at least one test will fail if removed. You don’t get that out of regular CSS classes, because naturally you think they are for attaching styles - not tests. To a lesser degree of certainty, it additionally indicates that an element in the markup is covered by tests.</p>
<p>This ultimately allows us to define certain rules, which we apply when we work with these classes.</p>
<h3 id="the-three-rules-for-working-with-buoys">The three rules for working with <strong>buoys</strong></h3>
<p>A <strong>buoy</strong> is a CSS class that starts with <code>test-</code>. In that way <strong>buoys</strong> make up a namespace within CSS.</p>
<ol type="1">
<li><p>From your tests (or specs), only refer to <strong>buoys</strong>, and give them meaningful names. Don’t use other CSS classes, nor other means of identifying elements in the markup.</p></li>
<li><p>Never attach any styles to <strong>buoys</strong>. <strong>buoys</strong> are for attaching tests, not styles.</p></li>
<li><p>When doing front-end work, like a redesign or changing markup, be careful to not lose any <strong>buoys</strong>. Make a list of the <strong>buoys</strong> you remove and put them back in when you’re done.</p></li>
</ol>
<p>These rules will make our tests resilient to redesigns. This means that our tests will stay intact while we change the markup or design. They will prevent you from getting false positives from your test suite where tests fail, while your feature still is working perfectly fine.</p>
<p>Happy testing!</p>
</div><div class="tags"><img class="tag-icon" src="/img/tag.svg"><ul itemprop="keywords"><li class="category"><a href="/category/coders tip.html">Coders Tip</a></li><li class="tag"><a href="/tags/testing.html">#testing</a></li></ul></div></div></article></div></main><footer><div itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><div class="name" itemprop="name">200ok GmbH</div><div itemprop="address" itemscope itemtype="https://schema.org/PostalAddress"><a href="https://goo.gl/maps/GNAoiNF7mbL2" title="View on Google Maps"><div itemprop="streetAddress">Badenerstrasse 313</div><div><span itemprop="postalCode">8003</span> <span itemprop="addressLocality">Zürich</span></div></a></div><div itemprop="telephone">+41 76 405 05 67</div><div itemprop="email"><a href="mailto:info@200ok.ch">info@200ok.ch</a></div><img itemprop="logo" src="https://200ok.ch/img/200ok.svg"></div></footer><div class="scripts" style="{:display &quot;none&quot;}"><script src="/js/vendor/bowser.min.js"></script><script async src="/js/ie_safeguard.js"></script><script async src="/js/tour.js"></script><script src="/js/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>tour=null</script></div></body></html>