I've always found the statistical techniques in modelling langauges quite distasteful!

I think there's a point of their usage viz to keep with with the changes but I'm more interested in the very start - computer science has a beautiful concept of turing-complete machine

this is a minimal machine which can execute all computations - algorithms - which can be computable i.e. it's only limited by limits of mathemtics - and logic..

I'm firmly convinced that Chomsky is pretty much on the right track ( for a long time now ) towards a better understanding - a better approach - towards modelling languages ...



first we need tools which generate languages ( how arbitrary would they be is an interesting question )

and then a complimentary mechanism to learn these generated languages - previously not encountered ! 


cellular automatons of grammar which can effectively produce all kinds of syntactic structures we come across in nature  it's all about the word and the sentential structures and morphologies - syntax driven semantics -

phew - so many new words - but they're aren't really new just that there's a lot of correlation between the fundamentals of computation and linguistics - 
